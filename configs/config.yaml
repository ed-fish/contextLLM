
# Example config.yaml
data:
  max_length: 300
  num_labels: 30520
  vocab_file: data/combined_files/combined_vocab.pkl
  topic_file: data/combined_files/keywords_vocab.pkl
  root_dir: /mnt/fast/nobackup/scratch4weeks/ef0036/
  frame_stride: 16
  downsample_rate: 0.25

model:
  tokenizer: pretrain_models/MBart_trimmed_yt_h2s
  transformer: pretrain_models/mytran_yt_h2s
  dino: pretrain_models/DINO/tmp.pth
  embed_dim: 1024
  sign_proj: True
  keywords_proj: True  # If True, dataset will load topics

training:
  wandb: online
  scale_embedding: False
  ckpt_path: "/home/ef0036/Projects/contextLLM/outputs/run_2025-02-18_00-10-30/best-epoch=002-val_total_loss=0.680.ckpt"
  labels: "gloss"

  # Settings for topic-based overlap
  use_topic_overlap: True            # If true, incorporate topic overlap into similarity matrix
  alpha_use_decay: True              # If true, we do linear decay of alpha
  topic_alpha_start: 1.0             # initial alpha
  topic_alpha_end: 0.0               # final alpha
  max_epochs: 50                     # used for scheduling alpha

save:
  output: outputs
  csv: csv_outputs/

